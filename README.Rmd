---
output: github_document
editor_options:
    chunk_output_type: console
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
	collapse = TRUE,
	comment = "#>",
	fig.path = "man/figures/README-",
	out.width = "100%"
)
# Quiet down
lgr::get_logger("mlr3")$set_threshold("warn")
options("xplain.progress" = FALSE)
set.seed(232323)
```

# `xplainfi`

<!-- badges: start -->

[![CRAN status](https://www.r-pkg.org/badges/version/xplainfi)](https://CRAN.R-project.org/package=xplainfi)
[![R-CMD-check](https://github.com/mlr-org/xplainfi/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/mlr-org/xplainfi/actions/workflows/R-CMD-check.yaml)
[![codecov](https://codecov.io/gh/mlr-org/xplainfi/graph/badge.svg?token=QIQDMP3AM7)](https://app.codecov.io/gh/mlr-org/xplainfi)

<!-- badges: end -->

The goal of `xplainfi` is to collect common feature importance methods under a
unified and extensible interface.

It is built around [mlr3](https://mlr-org.com/) as available abstractions for
learners, tasks, measures, etc. greatly simplify the implementation of
importance measures.

## Installation

Install `xplainfi` from CRAN:

```r
install.packages("xplainfi")
```

Or install `xplainfi` from [R-universe](https://mlr-org.r-universe.dev):

```r
install.packages("xplainfi", repos = c("https://mlr-org.r-universe.dev", "https://cloud.r-project.org"))
```

The latest development version of `xplainfi` can be installed with `pak`:

```r
# install.packages(pak)
pak::pak("mlr-org/xplainfi")
```

## Example: PFI

Here is a basic example on how to calculate PFI for a given learner and task,
using repeated cross-validation as resampling strategy and computing PFI within
each resampling 10 times on the `friedman1` task (see `?mlbench::mlbench.friedman1`).

The `friedman1` task has the following structure:

$$y = 10 \sin(\pi x_1 x_2) + 20(x_3 - 0.5)^2 + 10x_4 + 5x_5 + \varepsilon$$

Where $x_{\{1,2,3,4,5\}}$ are named `important1` through `important5` in the `Task`,
with additional numbered `unimportant` features without effect on $y$.

```{r setup}
library(xplainfi)
library(mlr3learners)

task = tgen("friedman1")$generate(1000)
learner = lrn("regr.ranger", num.trees = 100)
measure = msr("regr.mse")

pfi = PFI$new(
	task = task,
	learner = learner,
	measure = measure,
	resampling = rsmp("cv", folds = 3),
	n_repeats = 30
)
```

Compute and print PFI scores:

```{r pfi-compute}
pfi$compute()
pfi$importance()
```

If it aids interpretation, importances can also be calculated as the _ratio_
rather than the _difference_ between the baseline and post-permutation losses:

```{r pfi-ratio}
pfi$importance(relation = "ratio")
```

When PFI is computed based on resampling with multiple iterations, and / or
multiple permutation iterations, the individual scores can be retrieved as a
`data.table`:

```{r pfi-scores}
str(pfi$scores())
```

Where `iter_rsmp` corresponds to the resampling iteration, i.e., 3 for 3-fold
cross-validation, and `iter_repeat` corresponds to the permutation iteration
within each resampling iteration, 5 in this case. While `pfi$importance()`
contains the means across all iterations, `pfi$scores()` allows you to manually
visualize or aggregate them in any way you see fit.

For example:

```{r pfi-plot}
#| fig-width: 9
#| fig-height: 7
library(ggplot2)

ggplot(
	pfi$scores(),
	aes(x = importance, y = reorder(feature, importance))
) +
	geom_boxplot(color = "#f44560", fill = alpha("#f44560", 0.4)) +
	labs(
		title = "Permutation Feature Importance on Friedman1",
		subtitle = "Computed over 3-fold CV with 5 permutations per iteration using Random Forest",
		x = "Importance",
		y = "Feature"
	) +
	theme_minimal(base_size = 16) +
	theme(
		plot.title.position = "plot",
		panel.grid.major.y = element_blank()
	)
```

If the measure in question needs to be maximized rather than minimized (like
$R^2$), the internal importance calculation takes that into account via the
`$minimize` property of the measure and calculates importances such that the
intuition "performance improvement" -> "higher importance score" still holds:

```{r pfi-rsq}
pfi = PFI$new(
	task = task,
	learner = learner,
	measure = msr("regr.rsq")
)

pfi$compute()
pfi$importance()
```

See `vignette("xplainfi")` for more examples.
