---
title: "Inference for Feature Importance"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Inference for Feature Importance}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
	collapse = TRUE,
	comment = "#>",
	fig.width = 8,
	fig.height = 6
)
set.seed(123)
# Quiet down
lgr::get_logger("mlr3")$set_threshold("warn")
options("xplain.progress" = interactive())
```

```{r pkg}
library(xplainfi)
library(mlr3learners)
library(data.table)
library(ggplot2)
```

There are multiple (work in progress) inference methods available with the underlying implementation, but the API around them is still being worked out.

## Setup

We use a simple linear DGP for demonstration purposes where

- $X_1$ and $X_2$ are strongly correlated (r = 0.7)
- $X_1$ and $X_3$ have an effect on Y
- $X_2$ and $X_4$ don't have an effect 

```{r setup-data}
task = sim_dgp_correlated(n = 2000, r = 0.7)
learner = lrn("regr.ranger", num.trees = 500)
measure = msr("regr.mse")
```

```{r dag-correlated, echo=FALSE, fig.cap="DAG for correlated features DGP", fig.width=10, fig.height=4}
#| fig.alt: "Directed acyclic graph with four features X1-X4 and outcome Y. Bidirectional edge between X1 and X2. Arrows from X1 and X3 to Y."
DiagrammeR::grViz(
	"
  digraph Correlated {
    rankdir=LR;
    graph [ranksep=1.5];
    node [shape=circle, style=filled, fontsize=14, width=1.2];
    
    X1 [fillcolor='lightcoral', label='X₁\n(β=2.0)'];
    X2 [fillcolor='pink', label='X₂\n(β=0)'];
    X3 [fillcolor='lightblue', label='X₃\n(β=1.0)'];
    X4 [fillcolor='lightgray', label='X₄\n(β=0)'];
    Y [fillcolor='greenyellow', label='Y', width=1.5];
    
    X1 -> X2 [color=red, style=bold, dir=both, label='r = 0.7'];
    X1 -> Y [label='2.0'];
    X2 -> Y [style=dashed, color=gray, label='0'];
    X3 -> Y [label='1.0'];
    X4 -> Y [style=dashed, color=gray];
    
    {rank=source; X1; X3; X4}
    {rank=same; X2}
    {rank=sink; Y}
  }"
)
```

## Variance-correction

When we calculate PFI using an appropriate resampling, such as subsampling with 15 repeats, we can use the approach recommended by Molnar et al. (2023) based on the proposed correction by Nadeau & Bengio (2003).

By default, any importance measures' `$importance()` method will not output any variances or confidence intervals, it will merely compute averages over resampling iterations and repeats within resamplings (`iter_repeat` here).

```{r pfi-importance}
pfi = PFI$new(
	task = task,
	learner = learner,
	resampling = rsmp("subsampling", repeats = 15),
	measure = measure,
	n_repeats = 10 # for stability within resampling iters
)

pfi$compute()
pfi$importance()
```

If we want **unadjusted** confidence intervals based on a t-distribution, we can ask for them, but note these are too narrow / optimistic and hence invalid for inference:

```{r pfi-ci-raw}
pfi_ci_raw = pfi$importance(ci_method = "raw")
pfi_ci_raw
```

Analogously we can retrieve the **Nadeau & Bengio**-adjusted standard errors and derived confidence intervals which were demonstrated to have better (but still imperfect) coverage:

```{r pfi-ci-nadeau-bengio}
pfi_ci_corrected = pfi$importance(ci_method = "nadeau_bengio")
pfi_ci_corrected
```

## Empirical quantiles

Both `"raw"` and `"nadeau_bengio"` methods assume normally distributed importance scores and use parametric confidence intervals based on the t-distribution. As a alternative, we can use empirical quantiles to construct confidence-like intervals without any coverage guarantees.

```{r pfi-ci-quantile}
pfi_ci_quantile = pfi$importance(ci_method = "quantile")
pfi_ci_quantile
```

To highlight the differences between parametric and empirical approaches, we visualize all methods:

```{r pfi-ci-comparison}
#| fig.alt: "Point-and-whisker plot with features on y-axis and importance on x-axis. Three colored points for raw, nadeau_bengio, and quantile CI methods, each showing point estimates with horizontal error bars."
pfi_cis = rbindlist(
	list(
		pfi_ci_raw[, type := "raw"],
		pfi_ci_corrected[, type := "nadeau_bengio"],
		pfi_ci_quantile[, type := "quantile"]
	),
	fill = TRUE
)

ggplot(pfi_cis, aes(y = feature, color = type)) +
	geom_errorbar(
		aes(xmin = conf_lower, xmax = conf_upper),
		position = position_dodge(width = 0.6),
		width = .5
	) +
	geom_point(aes(x = importance), position = position_dodge(width = 0.6)) +
	scale_color_brewer(palette = "Set2") +
	labs(
		title = "Parametric & non-parametric CI methods",
		subtitle = "RF with 15 subsampling iterations",
		color = NULL
	) +
	theme_minimal(base_size = 14) +
	theme(legend.position = "bottom")
```

The results highlight just how optimistic the unadjusted, raw confidence intervals are.

## Conditional predictive impact (CPI)

CPI is implemented by [the cpi package](https://bips-hb.github.io/cpi/articles/intro.html), and provides conditional variable importance using knockoffs. 
It works with `mlr3` and its output on our data looks like this:

```{r cpi-setup}
library(cpi)

resampling = rsmp("cv", folds = 5)
resampling$instantiate(task)
```

```{r cpi-result}
cpi_res = cpi(
	task = task,
	learner = learner,
	resampling = resampling,
	measure = measure,
	test = "t"
)
setDT(cpi_res)
setnames(cpi_res, "Variable", "feature")
cpi_res[, method := "CPI"]

cpi_res
```

### CPI with knockoffs

Since `xplainfi` also includes knockoffs via the `KnockoffSampler` and the `KnockoffGaussianSampler`, the latter implementing the second order Gaussian knockoffs also used by default in `{cpi}`, we can recreate its results using `CFI` with the corresponding `sampler`.

`CFI` with a knockoff sampler supports CPI inference directly via `ci_method = "cpi"`:

```{r cfi-knockoff}
knockoff_gaussian = KnockoffGaussianSampler$new(task)

cfi = CFI$new(
	task = task,
	learner = learner,
	resampling = resampling,
	measure = measure,
	sampler = knockoff_gaussian
)

cfi$compute()

# CPI uses observation-wise losses with one-sided t-test by default
cfi_cpi_res = cfi$importance(ci_method = "cpi")
cfi_cpi_res

# Rename columns to match cpi package output for comparison
setnames(cfi_cpi_res, c("importance", "conf_lower"), c("CPI", "ci.lo"))
cfi_cpi_res[, method := "CFI+Knockoffs"]
```

The results should be very similar to those computed by `cpi()`, so let's compare them:

```{r cpi-cfi-plot}
#| fig.alt: "Point-and-whisker plot with features on y-axis and CPI values on x-axis. Two colored points for CPI and CFI+Knockoffs methods with horizontal error bars."
rbindlist(list(cpi_res, cfi_cpi_res), fill = TRUE) |>
	ggplot(aes(y = feature, x = CPI, color = method)) +
	geom_point(position = position_dodge(width = 0.3)) +
	geom_errorbar(
		aes(xmin = CPI, xmax = ci.lo),
		position = position_dodge(width = 0.3),
		width = 0.5
	) +
	scale_color_brewer(palette = "Dark2") +
	labs(
		title = "CPI and CFI with Knockoff sampler",
		subtitle = "RF with 5-fold CV",
		color = NULL
	) +
	theme_minimal(base_size = 14) +
	theme(legend.position = "top")

```

A noteable caveat of the knockoff approach is that they are not readily available for mixed data (with categorical features).

### CPI with ARF

An alternative is available using ARF as conditional sampler rather than knockoffs (see [Blesch et al. (2025)](https://doi.org/10.1609/aaai.v39i15.33712)), which we can perform analogously:

```{r cfi-arf}
arf_sampler = ConditionalARFSampler$new(
	task = task,
	finite_bounds = "local",
	min_node_size = 20,
	epsilon = 1e-15
)

cfi_arf = CFI$new(
	task = task,
	learner = learner,
	resampling = resampling,
	measure = measure,
	sampler = arf_sampler
)

cfi_arf$compute()

# CPI uses observation-wise losses with one-sided t-test
cfi_arf_res = cfi_arf$importance(ci_method = "cpi")
cfi_arf_res

# Rename columns to match cpi package output for comparison
setnames(cfi_arf_res, c("importance", "conf_lower"), c("CPI", "ci.lo"))
cfi_arf_res[, method := "CFI+ARF"]
```

We can now compare all three methods:

```{r cpi-cfi-arf-plot}
#| fig.alt: "Point-and-whisker plot with features on y-axis and CPI values on x-axis. Three colored points for CPI, CFI+Knockoffs, and CFI+ARF methods with horizontal error bars."
rbindlist(list(cpi_res, cfi_cpi_res, cfi_arf_res), fill = TRUE) |>
	ggplot(aes(y = feature, x = CPI, color = method)) +
	geom_point(position = position_dodge(width = 0.3)) +
	geom_errorbar(
		aes(xmin = CPI, xmax = ci.lo),
		position = position_dodge(width = 0.3),
		width = 0.5
	) +
	scale_color_brewer(palette = "Dark2") +
	labs(
		title = "CPI and CFI with Knockoffs and ARF",
		subtitle = "RF with 5-fold CV",
		color = NULL
	) +
	theme_minimal(base_size = 14) +
	theme(legend.position = "top")
```

As expected, the ARF-based approach differs more from both knockoff-based approaches, but they are all roughly in agreement.

### Statistical tests with CPI

CPI can also perform additional tests besides the default t-test, specifically the Wilcoxon-, Fisher-, or binomial test:

```{r cpi-tests}
#| fig.alt: "Point-and-whisker plot with features on y-axis and importance on x-axis. Four colored series for t, Wilcoxon, Fisher, and Binomial tests with horizontal error bars."
(cpi_res_wilcoxon = cfi_arf$importance(ci_method = "cpi", test = "wilcoxon"))
# Fisher test with same default for B as in cpi()
(cpi_res_fisher = cfi_arf$importance(ci_method = "cpi", test = "fisher", B = 1999))
(cpi_res_binom = cfi_arf$importance(ci_method = "cpi", test = "binomial"))

rbindlist(
	list(
		cfi_arf$importance(ci_method = "cpi")[, test := "t"],
		cpi_res_wilcoxon[, test := "Wilcoxon"],
		cpi_res_fisher[, test := "Fisher"],
		cpi_res_binom[, test := "Binomial"]
	),
	fill = TRUE
) |>
	ggplot(aes(y = feature, x = importance, color = test)) +
	geom_point(position = position_dodge(width = 0.3)) +
	geom_errorbar(
		aes(xmin = importance, xmax = conf_lower),
		position = position_dodge(width = 0.3),
		width = 0.5
	) +
	scale_color_brewer(palette = "Dark2") +
	labs(
		title = "CPI test with CFI/ARF",
		subtitle = "RF with 5-fold CV",
		color = "Test"
	) +
	theme_minimal(base_size = 14) +
	theme(legend.position = "top")
```

Given the width of the resulting confidence intervals, the Fisher- or t-test are generally recommended.


## Custom inference with LOCO

[Lei et al. (2018)](https://doi.org/10.1080/01621459.2017.1307116) proposed inference for LOCO using the median absolute differences of the baseline- and post-refit loss differences

$$
\theta_j = \mathrm{med}\left(
	|Y - \hat{f}_{n_1}^{-j}(X)| - |Y - \hat{f}_{n_1}(X)| \big| D_1
\right)
$$

If we apply `LOCO` as implemented in `xplainfi` using the median absolute error (MAE) as our measure including the median as the aggregation function, we unfortunately get something else, though:

```{r loco-mae}
measure_mae = msr("regr.mae")
measure_mae$aggregator = median

loco = LOCO$new(
	task = task,
	learner = learner,
	resampling = rsmp("holdout"),
	measure = measure_mae
)

loco$compute()
loco$importance()
```

This is **not** exactly what the authors propose, because `$score()` calculates the aggregation function (`median`) for each resampling iteration first, and takes the difference afterwards, i.e.

$$
\theta_j = \mathrm{med}\left(|Y - \hat{f}_{n_1}^{-j}(X)|\right) - \mathrm{med}\left(|Y - \hat{f}_{n_1}(X)| \big| D_1
\right)
$$

In the default case where the arithemtic mean is used, it does not matter whether we calculate the difference of the means or the mean of the differences, but using the median it does.

We can, however, reconstruct it by using the observation-wise losses (in this case, the absolute error):

```{r loco-obsloss}
loco_obsloss = loco$obs_loss()
head(loco_obsloss)
```

`obs_importance` here refers to the difference `loss_post - loss_baseline`, so

- $\texttt{loss_baseline} = |Y - \hat{f}_{n_1}(X)|$
- $\texttt{loss_post} = |Y - \hat{f}_{n_1}^{-j}(X)|$
- $\texttt{obs_importance} = \texttt{loss_post} - \texttt{loss_baseline}$

Which means by taking the median for each feature $j$ within each resampling iteration, we can construct $\theta_j(D_1)$ as proposed, for each set $D_k$ where $k$ is the resampling iteration:

```{r loco-thetas}
loco_thetas = loco_obsloss[, list(theta = median(obs_importance)), by = c("feature")]
loco_thetas
```

The authors then propose to construct distribution-free confidence intervals, e.g. using a sign- or Wilcoxon test
We can for example use `wilcoxon.test()` to compute confidence intervals around the estimated pseudo-median:

```{r loco-wilcox-ci}
loco_wilcox_ci = loco_obsloss[,
	{
		tt <- wilcox.test(
			obs_importance,
			conf.int = TRUE,
			conf.level = 0.95
		)
		.(
			statistic = tt$statistic,
			estimate = tt$estimate, # the pseudomedian importance
			p.value = tt$p.value,
			conf_lower = tt$conf.int[1],
			conf_upper = tt$conf.int[2]
		)
	},
	by = feature
]

loco_wilcox_ci
```
