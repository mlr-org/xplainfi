---
title: "Perturbation-based Feature Importance Methods"
editor_options: 
  chunk_output_type: console
---

```{r, include = FALSE}
knitr::opts_chunk$set(
	collapse = TRUE,
	comment = "#>",
	fig.width = 8,
	fig.height = 6
)
set.seed(123)
# Quiet down
lgr::get_logger("mlr3")$set_threshold("warn")
options("xplain.progress" = interactive())
```

```{r setup}
library(xplainfi)
library(mlr3)
library(mlr3learners)
library(data.table)
library(ggplot2)
library(DiagrammeR)
```

This vignette demonstrates the three perturbation-based feature importance methods implemented in xplainfi:

- **PFI (Permutation Feature Importance)**: Uses marginal sampling (simple permutation)
- **CFI (Conditional Feature Importance)**: Uses conditional sampling via Adversarial Random Forests
- **RFI (Relative Feature Importance)**: Uses conditional sampling on a user-specified subset of features

We'll demonstrate these methods using three carefully designed scenarios that highlight their key differences.

```{r setup-common}
# Common setup for all scenarios
learner <- lrn("regr.ranger", num.trees = 100)
resampling <- rsmp("cv", folds = 3)
measure <- msr("regr.mse")
```

## Scenario 1: Interaction Effects

This scenario demonstrates how marginal methods (PFI) can miss important interaction effects that conditional methods (CFI) capture:

```{r setup-interactions}
# Generate interaction scenario
task_int <- sim_dgp_interactions(n = 1000)
data_int <- task_int$data()
```

**Causal Structure:**

```{r dag-interactions, fig.width=8, fig.height=4, echo=FALSE}
#| fig.alt: "Directed acyclic graph with x1 and x2 connecting to a diamond-shaped interaction node, which connects to y. x3 connects directly to y."
grViz(
	"
digraph interaction_dag {
  rankdir=TB;
  node [shape=circle, style=filled, fontname='Arial', fontsize=12];
  
  # Feature nodes
  x1 [fillcolor='lightblue', label='x1'];
  x2 [fillcolor='lightblue', label='x2'];  
  x3 [fillcolor='lightblue', label='x3'];
  # noise1 [fillcolor='lightgray', label='noise1'];
  # noise2 [fillcolor='lightgray', label='noise2'];
  
  # Interaction node
  interaction [fillcolor='yellow', label='x1×x2', shape=diamond];
  
  # Outcome
  y [fillcolor='greenyellow', label='y'];
  
  # NO direct effects from x1 and x2
  x3 -> y [label='1.0', color='blue'];
  
  # Pure interaction effect
  x1 -> interaction [style=dashed];
  x2 -> interaction [style=dashed];
  interaction -> y [label='2.0', color='red', penwidth=3];
  
  # Layout
  {rank=same; x1, x2, x3, noise1, noise2}
  {rank=same; interaction}
}
"
)
```

The key insight: x1 and x2 have **NO direct effects** - they affect y ONLY through their interaction (thick red arrow). However, PFI will still show them as important because permuting either feature destroys the crucial interaction term.

### Analysis

Let's analyze the interaction scenario where $y = 2 \cdot x_1 \cdot x_2 + x_3 + \epsilon$. Note that x1 and x2 have NO main effects.

#### PFI on Interactions

```{r pfi-interactions}
#| cache: true
pfi_int <- PFI$new(
	task = task_int,
	learner = learner,
	measure = measure,
	resampling = resampling,
	n_repeats = 5
)

# Compute importance scores
pfi_int$compute()
pfi_int$importance(relation = "difference")
```

Expected: x1 and x2 will show high importance with PFI because permuting either feature destroys the interaction term x1×x2, which is crucial for prediction. This demonstrates a key limitation of PFI with interactions.

#### CFI on Interactions

CFI preserves the joint distribution, which should better capture the interaction effect:

```{r cfi-interactions}
#| cache: true
# Create ARF sampler for the interaction task
sampler_int = ConditionalARFSampler$new(task = task_int, finite_bounds = "local")

cfi_int <- CFI$new(
	task = task_int,
	learner = learner,
	measure = measure,
	resampling = resampling,
	n_repeats = 5,
	sampler = sampler_int
)

# Compute importance scores
cfi_int$compute()
cfi_int$importance(relation = "difference")
```

Expected: CFI should show somewhat lower importance for x1 and x2 compared to PFI because it better preserves the interaction structure during conditional sampling, providing a more nuanced importance estimate.

#### RFI on Interactions: Targeted Conditional Questions

RFI's unique strength is answering specific conditional questions. Let's explore what happens when we condition on different features:

```{r rfi-interactions}
#| cache: true
# RFI conditioning on x2: "How important is x1 given we know x2?"
rfi_int_x2 <- RFI$new(
	task = task_int,
	learner = learner,
	measure = measure,
	resampling = resampling,
	conditioning_set = "x2", # Condition on x2
	n_repeats = 5,
	sampler = sampler_int
)
rfi_int_x2$compute()

# RFI conditioning on x1: "How important is x2 given we know x1?"
rfi_int_x1 <- RFI$new(
	task = task_int,
	learner = learner,
	measure = measure,
	resampling = resampling,
	conditioning_set = "x1", # Condition on x1
	n_repeats = 5,
	sampler = sampler_int
)
rfi_int_x1$compute()
```

**RFI Results:**

- **x1 given x2**: `r sprintf("%.3f", rfi_int_x2$importance()[feature == "x1", importance])` (How important is x1 when we condition on x2)
- **x2 given x1**: `r sprintf("%.3f", rfi_int_x1$importance()[feature == "x2", importance])` (How important is x2 when we condition on x1)  
- **x3 given x2**: `r sprintf("%.3f", rfi_int_x2$importance()[feature == "x3", importance])` (How important is x3 when we condition on x2)

**Key insight**: In the pure interaction case (y = 2·x1·x2 + x3), when we condition on one interacting feature, the other becomes extremely important because they only matter together. This demonstrates RFI's power to answer targeted questions like "Given I already know x2, how much does x1 add?"

#### Comparing Methods on Interactions

Let's compare how the methods handle the interaction:

```{r compare-interactions}
#| echo: false
#| fig.alt: "Two grouped bar charts. First compares PFI (blue) and CFI (green) importance scores across features. Second shows RFI importance scores when conditioning on x2."

# Create comprehensive comparison including all methods
comp_all <- rbindlist(list(
	# PFI and CFI for all features
	pfi_int$importance()[, .(feature, importance, method = "PFI")],
	cfi_int$importance()[, .(feature, importance, method = "CFI")],
	# Selected RFI conditional results
	rfi_int_x2$importance()[feature == "x1", .(feature, importance, method = "RFI|x2")],
	rfi_int_x1$importance()[feature == "x2", .(feature, importance, method = "RFI|x1")],
	rfi_int_x2$importance()[feature == "x3", .(feature, importance, method = "RFI|x2")],
	# Add some noise features for completeness
	rfi_int_x2$importance()[
		feature %in% c("noise1", "noise2"),
		.(feature, importance, method = "RFI|x2")
	]
))

# Create comprehensive comparison plot
p1 <- ggplot(
	comp_all[method %in% c("PFI", "CFI")],
	aes(x = feature, y = importance, fill = method)
) +
	geom_col(position = "dodge", alpha = 0.8) +
	scale_fill_manual(values = c("PFI" = "steelblue", "CFI" = "darkgreen")) +
	labs(
		title = "PFI vs CFI on Interaction Effects",
		subtitle = "Marginal vs conditional sampling",
		y = "Importance Score",
		x = "Feature",
		fill = "Method"
	) +
	theme_minimal() +
	theme(legend.position = "bottom")

# Show RFI conditional results separately since they answer different questions
p2 <- ggplot(comp_all[method == "RFI|x2"], aes(x = feature, y = importance)) +
	geom_col(fill = "orange", alpha = 0.8) +
	labs(
		title = "RFI Conditioning on x2",
		subtitle = "How important is each feature given we know x2?",
		y = "Importance Score",
		x = "Feature"
	) +
	theme_minimal()

# Display both plots
p1
p2

# Store RFI results for inline text
rfi_x1_given_x2 <- rfi_int_x2$importance()[feature == "x1", importance]
rfi_x2_given_x1 <- rfi_int_x1$importance()[feature == "x2", importance]
rfi_x3_given_x2 <- rfi_int_x2$importance()[feature == "x3", importance]
```

### Key Insights: Interaction Effects

```{r summary-interactions}
# Combine results and calculate ratios
comp_int <- rbindlist(list(
	pfi_int$importance()[, .(feature, importance, method = "PFI")],
	cfi_int$importance()[, .(feature, importance, method = "CFI")]
))

# Calculate the ratio of CFI to PFI importance for interacting features
int_ratio <- dcast(comp_int[feature %in% c("x1", "x2")], feature ~ method, value.var = "importance")
int_ratio[, cfi_pfi_ratio := CFI / PFI]
setnames(int_ratio, c("PFI", "CFI"), c("pfi_importance", "cfi_importance"))

int_ratio |>
	knitr::kable(
		digits = 3,
		caption = "CFI vs PFI for Interacting Features"
	)
```

While x1 and x2 have no main effects, PFI still correctly identifies them as important because permuting either feature destroys the interaction term x1×x2, which is crucial for prediction.

## Scenario 2: Confounding

This scenario shows how hidden confounders affect importance estimates and how conditioning can help:

```{r setup-confounding}
# Generate confounding scenario
task_conf <- sim_dgp_confounded(n = 1000)
data_conf <- task_conf$data()
```

**Causal Structure:**

```{r dag-confounding, fig.width=8, fig.height=5, echo=FALSE}
#| fig.alt: "Directed acyclic graph with hidden confounder H at top connecting via red arrows to x1, proxy, and y. Blue arrows show x1 to y and independent to y."
grViz(
	"
digraph confounding_dag {
  rankdir=TB;
  node [shape=circle, style=filled, fontname='Arial', fontsize=12];

  # Hidden confounder
  H [fillcolor='red', label='Hidden\\nConfounder', fontcolor='white'];

  # Observed features
  x1 [fillcolor='lightblue', label='x1'];
  proxy [fillcolor='orange', label='proxy'];
  independent [fillcolor='lightblue', label='independent'];

  # Outcome
  y [fillcolor='greenyellow', label='y'];

  # Confounding paths (creating spurious correlations)
  H -> x1 [label='1.0', color='red'];
  H -> proxy [label='1.0', color='red'];
  H -> y [label='1.0', color='red', penwidth=2];

  # Direct causal effects
  x1 -> y [label='1.0', color='blue'];
  independent -> y [label='1.0', color='blue'];

  # Layout
  {rank=same; x1, proxy, independent}
}
"
)
```

The red arrows show the confounding paths: the hidden confounder creates spurious correlations between x1, proxy, and y. The **blue arrows** show true direct causal effects. Note that `independent` is truly independent (no confounding) while `proxy` provides a noisy measurement of the confounder.

In the observable confounder scenaro (used later), the confounder H would be included as a feature in the dataset, allowing direct conditioning rather than relying on the noisy proxy.

```{r viz-confounding}
#| echo: false
#| fig.alt: "Heatmap showing correlation matrix between x1, proxy, independent, and y. Cells colored from blue (negative) through white to red (positive) with correlation values displayed."
# Visualize confounding structure
cor_data <- cor(data_conf[, .(x1, proxy, independent, y)])
# Convert correlation matrix to long format for ggplot
cor_df <- data.table(
	var1 = rep(rownames(cor_data), each = ncol(cor_data)),
	var2 = rep(colnames(cor_data), nrow(cor_data)),
	correlation = as.vector(cor_data)
)

ggplot(cor_df, aes(x = var1, y = var2, fill = correlation)) +
	geom_tile(color = "white") +
	geom_text(aes(label = round(correlation, 2)), size = 3) +
	scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0) +
	labs(
		title = "Correlation Structure with Hidden Confounder",
		subtitle = "Note high correlations between x1 and proxy due to confounder"
	) +
	theme_minimal() +
	theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

The hidden confounder creates spurious correlations between x1 and y (red paths), making x1 appear more important than its true direct effect. RFI conditioning on the proxy (which measures the confounder) should help isolate the true direct effect (blue path).

### Analysis

Now let's analyze the confounding scenario where a hidden confounder affects both features and the outcome.

#### PFI on Confounded Data

```{r pfi-confounding}
#| cache: true
pfi_conf <- PFI$new(
	task = task_conf,
	learner = learner,
	measure = measure,
	resampling = resampling,
	n_repeats = 5
)

pfi_conf$compute()
pfi_conf$importance()
```

#### RFI Conditioning on Proxy

RFI can condition on the proxy to help isolate direct effects:

```{r rfi-confounding}
#| cache: true
# Create sampler for confounding task
sampler_conf = ConditionalARFSampler$new(
	task = task_conf,
	verbose = FALSE,
	finite_bounds = "local"
)

# RFI conditioning on the proxy
rfi_conf <- RFI$new(
	task = task_conf,
	learner = learner,
	measure = measure,
	resampling = resampling,
	conditioning_set = "proxy", # Condition on proxy to reduce confounding
	n_repeats = 5,
	sampler = sampler_conf
)

rfi_conf$compute()
rfi_conf$importance()
```

#### Also trying CFI for comparison

```{r cfi-confounding}
#| cache: true
cfi_conf <- CFI$new(
	task = task_conf,
	learner = learner,
	measure = measure,
	resampling = resampling,
	n_repeats = 5,
	sampler = sampler_conf
)

cfi_conf$compute()
cfi_conf$importance()
```

#### Observable Confounder Scenario

In many real-world situations, confounders are actually observable (e.g., demographics, baseline characteristics). Let's explore how RFI performs when we can condition directly on the true confounder:

```{r observable-confounder}
#| cache: true
# Generate scenario where confounder is observable
task_conf_obs <- sim_dgp_confounded(n = 1000, hidden = FALSE)

# Now we can condition directly on the true confounder
sampler_conf_obs = ConditionalARFSampler$new(
	task = task_conf_obs,
	verbose = FALSE,
	finite_bounds = "local"
)

# RFI conditioning on the true confounder (not just proxy)
rfi_conf_obs <- RFI$new(
	task = task_conf_obs,
	learner = learner,
	measure = measure,
	resampling = resampling,
	conditioning_set = "confounder", # Condition on true confounder
	n_repeats = 5,
	sampler = sampler_conf_obs
)

rfi_conf_obs$compute()
rfi_conf_obs$importance()

# Compare with PFI on the same data
pfi_conf_obs <- PFI$new(
	task = task_conf_obs,
	learner = learner,
	measure = measure,
	resampling = resampling,
	n_repeats = 5
)
pfi_conf_obs$compute()
pfi_conf_obs$importance()
```


- **x1 importance**: PFI = `r sprintf("%.3f", pfi_conf_obs$importance()[feature == "x1", importance])`, RFI|confounder = `r sprintf("%.3f", rfi_conf_obs$importance()[feature == "x1", importance])`
- **independent importance**: PFI = `r sprintf("%.3f", pfi_conf_obs$importance()[feature == "independent", importance])`, RFI|confounder = `r sprintf("%.3f", rfi_conf_obs$importance()[feature == "independent", importance])`

When conditioning on the true confounder, RFI should show reduced importance for x1 (since much of its apparent importance was due to confounding) while independent maintains its importance (since it's truly causally related to y).

#### Comparing Methods on Confounding

```{r compare-confounding}
#| echo: false
#| fig.alt: "Two grouped bar charts. First shows PFI (blue), CFI (green), and RFI (orange) importance by feature. Second compares PFI and RFI when confounder is observed."
# Combine all results
comp_conf_long <- rbindlist(list(
	pfi_conf$importance()[, .(feature, importance, method = "PFI")],
	cfi_conf$importance()[, .(feature, importance, method = "CFI")],
	rfi_conf$importance()[, .(feature, importance, method = "RFI")]
))

ggplot(comp_conf_long, aes(x = feature, y = importance, fill = method)) +
	geom_col(position = "dodge", alpha = 0.8) +
	scale_fill_manual(values = c("PFI" = "steelblue", "CFI" = "darkgreen", "RFI" = "orange")) +
	labs(
		title = "Feature Importance Under Confounding",
		subtitle = "RFI conditions on proxy to reduce confounding bias",
		y = "Importance Score",
		x = "Feature",
		fill = "Method"
	) +
	theme_minimal() +
	theme(legend.position = "bottom")

comp_conf_obs_long <- rbindlist(list(
	pfi_conf_obs$importance()[, .(feature, importance, method = "PFI")],
	rfi_conf_obs$importance()[, .(feature, importance, method = "RFI")]
))

ggplot(comp_conf_obs_long, aes(x = feature, y = importance, fill = method)) +
	geom_col(position = "dodge", alpha = 0.8) +
	scale_fill_manual(values = c("PFI" = "steelblue", "RFI" = "orange")) +
	labs(
		title = "Feature Importance Under Observed Confounding",
		subtitle = "RFI conditions on confounder to reduce confounding bias",
		y = "Importance Score",
		x = "Feature",
		fill = "Method"
	) +
	theme_minimal() +
	theme(legend.position = "bottom")
```

### Confounding Effects

```{r summary-confounding}
# Show how conditioning affects importance estimates
conf_wide <- dcast(comp_conf_long, feature ~ method, value.var = "importance")
conf_summary <- conf_wide[, .(
	feature,
	pfi_importance = round(PFI, 3),
	cfi_importance = round(CFI, 3),
	rfi_proxy_importance = round(RFI, 3),
	pfi_rfi_diff = round(PFI - RFI, 3)
)]

conf_summary |>
	knitr::kable(
		caption = "Effect of Conditioning on Proxy in Confounded Scenario"
	)
```

In the confounding scenario, we observed:

1. **PFI shows confounded effects**: Without accounting for confounders, PFI overestimates the importance of x1 due to its spurious correlation with y through the hidden confounder.

2. **RFI conditioning on proxy reduces bias**: By conditioning on the proxy (noisy measurement of the confounder), RFI can partially isolate direct effects, though some confounding remains due to measurement error.

3. **RFI conditioning on true confounder removes bias**: When the confounder is observable and we can condition directly on it, RFI dramatically reduces the apparent importance of x1, revealing its true direct effect.

4. **CFI partially accounts for confounding**: Through its conditional sampling, CFI captures some of the confounding structure but cannot target specific confounders like RFI can.

## Scenario 3: Correlated Features

This scenario demonstrates the fundamental difference between marginal and conditional methods when features are highly correlated:

```{r setup-correlated}
# Generate correlated features scenario
task_cor <- sim_dgp_correlated(n = 1000)
data_cor <- task_cor$data()
```

**Causal Structure:**

```{r dag-correlated, fig.width=6, fig.height=4, echo=FALSE}
#| fig.alt: "Directed acyclic graph with four features. Bidirectional dashed purple edge between x1 and x2. Arrows from x1 and x3 to y."
grViz(
	"
digraph correlated_dag {
  rankdir=TB;
  node [shape=circle, style=filled, fontname='Arial', fontsize=12];
  
  # Feature nodes
  x1 [fillcolor='lightblue', label='x1'];
  x2 [fillcolor='lightblue', label='x2'];
  x3 [fillcolor='lightblue', label='x3'];
  x4 [fillcolor='lightgray', label='x4'];
  
  # Outcome
  y [fillcolor='greenyellow', label='y'];
  
  # Direct effects
  x1 -> y [label='2.0', color='blue'];
  x3 -> y [label='1.0', color='blue'];
  # x2 has NO direct effect on y despite high correlation with x1
  
  # Correlation between x1 and x2 (bidirectional dashed line)
  x1 -> x2 [dir=both, style=dashed, color='purple', label='r=0.9'];
  
  # Layout
  {rank=same; x1, x2, x3, x4}
}
"
)
```

x1 and x2 are highly correlated (r = 0.9 from MVN) but only x1 has a causal effect on y. x2 is a spurious predictor - correlated with the causal feature but not causal itself.

### Analysis

Let's analyze how different methods handle highly correlated features:

#### PFI on Correlated Features

```{r pfi-correlated}
#| cache: true
pfi_cor <- PFI$new(
	task = task_cor,
	learner = learner,
	measure = measure,
	resampling = resampling,
	n_repeats = 5
)

pfi_cor$compute()
pfi_cor$importance()
```

Expected: PFI will show high importance for BOTH x1 and x2, even though only x1 has a true causal effect. This happens because x2 is highly correlated with x1, so permuting x2 destroys predictive information about x1.

#### CFI on Correlated Features

```{r cfi-correlated}
#| cache: true
# Create ARF sampler for correlated task
sampler_cor = ConditionalARFSampler$new(task = task_cor, finite_bounds = "local")

cfi_cor <- CFI$new(
	task = task_cor,
	learner = learner,
	measure = measure,
	resampling = resampling,
	n_repeats = 5,
	sampler = sampler_cor
)

cfi_cor$compute()
cfi_cor$importance()
```

Expected: CFI should show high importance for x1 (the true causal feature) but near-zero importance for x2 (the spurious correlated feature) because conditional sampling preserves the correlation structure and can distinguish between causal and spurious predictors.

#### RFI to Answer Conditional Questions

```{r rfi-correlated}
#| cache: true
# RFI conditioning on x1: "How important is x2 given we know x1?"
rfi_cor_x1 <- RFI$new(
	task = task_cor,
	learner = learner,
	measure = measure,
	resampling = resampling,
	conditioning_set = "x1",
	n_repeats = 5,
	sampler = sampler_cor
)
rfi_cor_x1$compute()

# RFI conditioning on x2: "How important is x1 given we know x2?"
rfi_cor_x2 <- RFI$new(
	task = task_cor,
	learner = learner,
	measure = measure,
	resampling = resampling,
	conditioning_set = "x2",
	n_repeats = 5,
	sampler = sampler_cor
)
rfi_cor_x2$compute()
```

- **x2 given x1**: `r sprintf("%.3f", rfi_cor_x1$importance()[feature == "x2", importance])` (How much does x2 add when we already know x1?)
- **x1 given x2**: `r sprintf("%.3f", rfi_cor_x2$importance()[feature == "x1", importance])` (How much does x1 add when we already know x2?)

Expected: When conditioning on x1, the importance of x2 should be near zero (and vice versa) because they're almost identical - knowing one tells you almost everything about the other.

#### Comparing Methods on Correlated Features

```{r compare-correlated}
#| echo: false
#| fig.alt: "Grouped bar chart comparing PFI (blue) and CFI (green) importance scores for each feature x1 through x4."
# Combine results
comp_cor_long <- rbindlist(list(
	pfi_cor$importance()[, .(feature, importance, method = "PFI")],
	cfi_cor$importance()[, .(feature, importance, method = "CFI")]
))

# Add selected RFI results
comp_cor_rfi <- rbindlist(list(
	rfi_cor_x1$importance()[feature == "x2", .(feature = "x2|x1", importance, method = "RFI")],
	rfi_cor_x2$importance()[feature == "x1", .(feature = "x1|x2", importance, method = "RFI")]
))

ggplot(comp_cor_long, aes(x = feature, y = importance, fill = method)) +
	geom_col(position = "dodge", alpha = 0.8) +
	scale_fill_manual(values = c("PFI" = "steelblue", "CFI" = "darkgreen")) +
	labs(
		title = "PFI vs CFI on Highly Correlated Features",
		subtitle = "x1 and x2 have correlation r ≈ 0.9 (from MVN), only x1 is causal",
		y = "Importance Score",
		x = "Feature",
		fill = "Method"
	) +
	theme_minimal() +
	theme(legend.position = "bottom")

# Calculate the ratio of CFI to PFI for correlated features
cor_ratio <- dcast(
	comp_cor_long[feature %in% c("x1", "x2")],
	feature ~ method,
	value.var = "importance"
)
cor_ratio[, cfi_pfi_ratio := CFI / PFI]
```

### Correlated Features

```{r summary-correlated}
cor_ratio |>
	knitr::kable(
		digits = 3,
		caption = "CFI vs PFI for Highly Correlated Features"
	)
```

In the correlated features scenario:

1. **PFI overestimates importance of spurious features**: PFI assigns high importance to BOTH x1 (causal) and x2 (spurious) because they're highly correlated. Permuting x2 destroys information about x1, making x2 appear important even though it has no causal effect.

2. **CFI correctly identifies causal features**: By preserving the correlation structure during conditional sampling, CFI can distinguish between x1 (truly causal) and x2 (merely correlated), assigning high importance only to x1.

3. **RFI reveals redundancy**: When conditioning on x1, the additional importance of x2 is near zero (and vice versa), correctly identifying their redundancy for prediction.

4. **Practical implication**: PFI would mislead you to think both features are important. CFI correctly shows that only x1 is truly important, while x2 is just along for the ride due to correlation.

## Scenario 4: Independent Features (Baseline)

To provide a baseline comparison, let's examine a scenario where all feature importance methods should produce similar results:

```{r setup-independent}
# Generate independent features scenario
task_ind <- sim_dgp_independent(n = 1000)
data_ind <- task_ind$data()
```

**Causal Structure:**

```{r dag-independent, fig.width=6, fig.height=4, echo=FALSE}
#| fig.alt: "Directed acyclic graph with five independent feature nodes at top, each with arrows to outcome y. Arrow thickness varies by effect size."
grViz(
	"
digraph independent_dag {
  rankdir=TB;
  node [shape=circle, style=filled, fontname='Arial', fontsize=12];
  
  # Feature nodes
  important1 [fillcolor='lightblue', label='important1'];
  important2 [fillcolor='lightblue', label='important2'];
  important3 [fillcolor='lightblue', label='important3'];
  unimportant1 [fillcolor='lightgray', label='unimportant1'];
  unimportant2 [fillcolor='lightgray', label='unimportant2'];
  
  # Outcome
  y [fillcolor='greenyellow', label='y'];
  
  # Direct effects only - no interactions or confounding
  important1 -> y [label='2.0', color='blue'];
  important2 -> y [label='1.0', color='blue'];
  important3 -> y [label='0.5', color='blue'];
  
  # No edge from unimportant features to y
  
  # Layout
  {rank=same; important1, important2, important3, unimportant1, unimportant2}
}
"
)
```

This is the **simplest scenario**: all features are independent, there are no interactions, and no confounding. Each feature has only a direct effect on y (or no effect in the case of noise).

### Running All Methods on Independent Features

First PFI:

```{r all-methods-independent-pfi}
#| cache: true
# PFI
pfi_ind <- PFI$new(
	task = task_ind,
	learner = learner,
	measure = measure,
	resampling = resampling,
	n_repeats = 5
)
pfi_ind$compute()
```

Now CFI  with the ARF sampler:

```{r all-methods-independent-cfi}
#| cache: true
sampler_ind = ConditionalARFSampler$new(task = task_ind, finite_bounds = "local")
cfi_ind <- CFI$new(
	task = task_ind,
	learner = learner,
	measure = measure,
	resampling = resampling,
	n_repeats = 5,
	sampler = sampler_ind
)
cfi_ind$compute()
```

RFI with empty conditioning set, basically equivalent to PFI with a different sampler:

```{r all-methods-independent-rfi}
#| cache: true
rfi_ind <- RFI$new(
	task = task_ind,
	learner = learner,
	measure = measure,
	resampling = resampling,
	conditioning_set = character(0), # Empty set
	n_repeats = 5,
	sampler = sampler_ind
)
rfi_ind$compute()
```

And now we visualize:

```{r combine-rf-plot}
#| echo: false
#| fig.alt: "Grouped bar chart comparing PFI (blue), CFI (green), and RFI (orange) importance scores across five features."
# Combine results using rbindlist
comp_ind_long <- rbindlist(list(
	pfi_ind$importance()[, .(feature, importance, method = "PFI")],
	cfi_ind$importance()[, .(feature, importance, method = "CFI")],
	rfi_ind$importance()[, .(feature, importance, method = "RFI")]
))

ggplot(comp_ind_long, aes(x = feature, y = importance, fill = method)) +
	geom_col(position = "dodge", alpha = 0.8) +
	scale_fill_manual(values = c("PFI" = "steelblue", "CFI" = "darkgreen", "RFI" = "orange")) +
	labs(
		title = "Feature Importance: Independent Features (Baseline)",
		subtitle = "All methods should produce similar results with independent features",
		y = "Importance Score",
		x = "Feature",
		fill = "Method"
	) +
	theme_minimal() +
	theme(legend.position = "bottom")
```

### Agreement Between Methods

```{r agreement-independent}
# Calculate coefficient of variation for each feature across methods
comp_ind_wide <- dcast(comp_ind_long, feature ~ method, value.var = "importance")
comp_ind_wide[,
	`:=`(
		mean_importance = rowMeans(.SD),
		sd_importance = apply(.SD, 1, sd),
		cv = apply(.SD, 1, sd) / rowMeans(.SD)
	),
	.SDcols = c("PFI", "CFI", "RFI")
]

comp_ind_wide[, .(
	feature,
	mean_importance = round(mean_importance, 3),
	cv = round(cv, 3),
	agreement = ifelse(cv < 0.1, "High", ifelse(cv < 0.2, "Moderate", "Low"))
)] |>
	knitr::kable(
		caption = "Method Agreement on Independent Features",
		col.names = c("Feature", "Mean Importance", "Coef. of Variation", "Agreement Level")
	)
```

With independent features and no complex relationships, all three methods (PFI, CFI, RFI) produce very similar importance estimates. This confirms that the differences we observe in Scenarios 1 and 2 are truly due to interactions and confounding, not artifacts of the methods themselves.

## Key Takeaways

Through these four scenarios, we've demonstrated:

1. **Method choice matters**: 
   - **PFI** is simple and fast but can miss interaction effects, underestimate importance of correlated features, and be affected by confounding
   - **CFI** captures feature dependencies and interactions through conditional sampling, correctly handling correlated features
   - **RFI** allows targeted conditioning to isolate specific relationships and reveal redundancy

2. **When to use each method**:
   - Use **PFI** when features are believed to be independent (as in Scenario 4) and you want a quick baseline importance ranking
   - Use **CFI** when you suspect feature interactions, correlations, or dependencies (as in Scenarios 1 & 3) and want a sophisticated analysis that respects feature relationships
   - Use **RFI** when you have specific conditional questions: "How important is feature X given I already know feature Y?" (as in Scenarios 1, 2 & 3). Essential for feature selection and understanding incremental value.

3. **Practical considerations**:
   - All methods benefit from cross-validation and multiple permutation iterations for stability
   - ARF-based conditional sampling (used in CFI/RFI) is more computationally intensive than marginal sampling
   - The choice of conditioning set in RFI requires domain knowledge

## Further Reading

For more details on these methods and their theoretical foundations, see:

- Breiman (2001) for the original PFI formulation
- Strobl et al. (2008) for limitations of PFI with correlated features  
- Watson & Wright (2021) for conditional sampling with ARF
- König et al. (2021) for relative feature importance
- Ewald et al. (2024) for a comprehensive review of feature importance methods
